# Turn on text-mode installation (little faster than GUI)
# text

authselect --enableshadow --passalgo=sha512
keyboard --vckeymap=us --xlayouts='us'
lang en-US.UTF-8
network --bootproto=dhcp --activate --onboot=yes
firewall --enabled
timezone America/Boise --isUtc
selinux --enforcing
firstboot --disable
eula --agreed

rootpw --iscrypted $1$CuzB8BHE$Nq/aKn1GZTVIhneYoKlMw/
user --name=jhieb --iscrypted --groups=wheel --password=$1$CuzB8BHE$Nq/aKn1GZTVIhneYoKlMw/

reboot

%post --interpreter=/usr/bin/python3 --log=/root/setup.log

import subprocess

# Repo additions/changes.
kubeadm_repo = """
[kubernetes]
name=Kubernetes
baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64
enabled=1
gpgcheck=1
gpgkey=https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
exclude=kubelet kubeadm kubectl
"""

with open("/etc/yum.repos.d/kubernetes.repo","w+") as f:
    f.writelines(kubeadm_repo)

# various network and CRI settings that will help.
containerd_conf = """overlay
br_netfilter
"""

with open("/etc/modules-load.d/containerd.conf","w+") as f:
    f.writelines(containerd_conf)

k8s_cri_conf = """net.bridge.bridge-nf-call-iptables  = 1
net.ipv4.ip_forward                 = 1
net.bridge.bridge-nf-call-ip6tables = 1
"""

with open("/etc/sysctl.d/99-kubernetes-cri.conf","w+") as f:
    f.writelines(k8s_cri_conf)

# https://github.com/kubernetes/kubernetes/issues/76146
#cat > /etc/sysctl.d/k8s-ipv6.conf <<EOF
#net.ipv6.conf.all.disable_ipv6 = 0
#net.ipv6.conf.default.disable_ipv6 = 0
#EOF
#sysctl --system
#If not works, could try this:
#
#cat > /etc/sysctl.d/k8s-ipv6.conf <EOF
#net.ipv6.conf.all.disable_ipv6 = 1
#net.ipv6.conf.default.disable_ipv6 = 1
#EOF
#sysctl --system

subprocess.run("sysctl --system", shell=True)

# Set SELinux in permissive mode (effectively disabling it)
subprocess.run("setenforce 0", shell=True)
subprocess.run("sed -i 's/^SELINUX=enforcing$/SELINUX=permissive/' /etc/selinux/config", shell=True)

# Open up firewall ports
subprocess.run("firewall-cmd --permanent --add-port=6443/tcp", shell=True)
subprocess.run("firewall-cmd --permanent --add-port=2379/tcp", shell=True)
subprocess.run("firewall-cmd --permanent --add-port=2380/tcp", shell=True)
subprocess.run("firewall-cmd --permanent --add-port=10250/tcp", shell=True)
subprocess.run("firewall-cmd --permanent --add-port=10257/tcp", shell=True)
subprocess.run("firewall-cmd --permanent --add-port=10259/tcp", shell=True)

subprocess.run("dnf install docker -y", shell=True)
subprocess.run("dnf install git -y", shell=True)
subprocess.run("dnf install kubeadm --disableexcludes=kubernetes -y", shell=True)
subprocess.run("dnf install kubectl --disableexcludes=kubernetes -y", shell=True)
subprocess.run("dnf install kubelet --disableexcludes=kubernetes -y", shell=True)

# Remove the swap generation by default on ZFS in fedora.
subprocess.run("dnf remove zram-generator-defaults -y", shell=True)

subprocess.run("systemctl enable docker", shell=True)
subprocess.run("systemctl start docker", shell=True)
subprocess.run("systemctl enable containerd", shell=True)
subprocess.run("systemctl start containerd", shell=True)
subprocess.run("systemctl enable kubelet", shell=True)

subprocess.run("containerd config default | tee /etc/containerd/config.toml > /dev/null", shell=True)
subprocess.run("sed -i 's/SystemdCgroup \= false/SystemdCgroup \= true/g' /etc/containerd/config.toml", shell=True)
subprocess.run("systemctl daemon-reload", shell=True)
subprocess.run("systemctl start containerd", shell=True)

# TODO remove but just making sure firewall port blocking isn't messing with me.
subprocess.run("systemctl disable firewalld", shell=True)
subprocess.run("systemctl stop firewalld", shell=True)

%end

## NOTE!!!! it appears that BTRFS has issues with k8s so when setting up storage use ext4 - https://github.com/kubernetes/minikube/issues/9982
# TODO move this chunk into a script that the above step writes so we can ca        ll in OS?
# IT'S IMPORTANT TO SSH INTO NODE SO YOU CAN COPY kubeadm init LOG TO NOTES INCLUDING NODE JOIN TOKEN!!!
# To be run in OS
# First reboot set the hostname (something unique)
# sudo hostnamectl set-hostname fedora-control-plane
# sudo swapoff -a # TODO make permanent?
# sudo setenforce 0
# sudo kubeadm init --pod-network-cidr=192.168.1.1/24  # we might need more arguments with regard to multi-control plane + CIDR.
# mkdir -p $HOME/.kube
# sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
# sudo chown $(id -u):$(id -g) $HOME/.kube/config

# Which networks work best?

# fedora 36 network example - kubectl apply -f https://raw.githubusercontent.com/cloudnativelabs/kube-router/master/daemonset/kubeadm-kuberouter.yaml



# For some reason i have to restart containerd + kubelet and it seemed to stabilize a bit after kubeadm init - https://github.com/k3s-io/k3s/issues/1857
# systemctl restart containerd
# systemctl restart kubelet

# This seems to be my problem - https://stackoverflow.com/questions/49017719/kubernetes-kube-system-pods-in-master-node-keep-restarting-after-worker-node-j
# The server hostname is duplicate to another VM.

# This could also be it- https://serverfault.com/questions/1110150/all-kube-system-pods-keep-crashing-etcd-receives-sigterm
# GRUB_CMDLINE_LINUX_DEFAULT="systemd.unified_cgroup_hierarchy=0" to /etc/default/grub

# https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/troubleshooting-kubeadm/
# try disabling selinux??
# try disabling firewall??
# Might have to deploy the network add on to resolve the states

# simple networking add.  https://dev.to/carminezacc/creating-a-kubernetes-cluster-with-fedora-coreos-36-j17
# kubectl apply -f https://raw.githubusercontent.com/cloudnativelabs/kube-router/master/daemonset/kubeadm-kuberouter.yaml

# more random tutorials on kubeadm - https://devopscube.com/setup-kubernetes-cluster-kubeadm/

# This has a lot of great details on the setup + constant crashing - https://github.com/kubernetes/kubernetes/issues/112622

# should i try ubuntu debian at this point?  This is getting frustrating.

# I've seen this error on the apiserver - https://github.com/kubernetes/kubernetes/issues/76146